# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""The core engine for generating Terraform artifacts from a complete.json.

This module defines the TerraformArtifactGenerator class, which encapsulates the
logic for transforming a complete configuration dictionary into various
Terraform file formats using Jinja2 templates.
"""

import collections
from collections.abc import Mapping
import logging
import os
import re
from typing import Any, List
from urllib import parse

from . import jinja_renderer


DefaultDict = collections.defaultdict
urlparse = parse.urlparse
logger = logging.getLogger(__name__)

PRODUCERS_YAML_OUTPUT_DIR_NAME = "producer"
CONSUMERS_YAML_OUTPUT_DIR_NAME = "consumer"
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATES_BASE_DIR = os.path.join(os.path.dirname(SCRIPT_DIR), "configuration")


def _extract_api_service_name(discoveryUrl: str) -> str | None:
    """Extracts the API service name (e.g., compute.googleapis.com)."""
    try:
        parsed_url = urlparse(discoveryUrl)
    except ValueError:
        logger.warning("Could not parse discovery URL: %s", discoveryUrl)
        return None

    hostname = parsed_url.netloc
    if hostname == "www.googleapis.com":
        match = re.search(r"/discovery/v1/apis/([^/]+)/", parsed_url.path)
        return f"{match.group(1)}.googleapis.com" if match else None
    elif hostname.endswith(".googleapis.com"):
        return hostname
    return None


class TerraformArtifactGenerator:
    """Generates Terraform files from a complete configuration dictionary."""

    def __init__(
        self,
        complete_config: Mapping[str, Any],
        supported_resources: Mapping[str, Any],
        templates_base_dir: str,
    ):
        """Initializes the TerraformArtifactGenerator engine.

        Args:
          complete_config: A dictionary representing the complete, processed JSON
            configuration. The generator relies on this dictionary having a specific
            structure, including a top-level 'projects' key containing a list of
            project dictionaries. Each project dictionary is expected to have a
            'project-id' and may contain lists of resources such as 'producers',
            'consumers', 'vpc', 'subnets', and 'forwardingRules'.
          supported_resources: A dictionary of supported resource metadata, loaded
            from supported_resources.json.
          templates_base_dir: The base directory where Jinja2 templates are located.
        """
        self._config = complete_config
        self._supported_resources = supported_resources
        self._templates_base_dir = templates_base_dir
        self._generated_files: List[str] = []

    def get_generated_files(self) -> List[str]:
        """Returns the list of all file paths generated by this instance."""
        return self._generated_files

    def _add_generated_file(self, file_path: str):
        """A helper to track a newly generated file."""
        if file_path not in self._generated_files:
            self._generated_files.append(file_path)

    def write_file(self, output_path: str, content: str | None) -> bool:
        """Writes content to a file and tracks it.

        This is the public interface for all file writing.

        Args:
          output_path: The full path of the file to write.
          content: The string content to write to the file.

        Returns:
          True if the file was written successfully, False otherwise.
        """
        if content is None:
            logger.error("Attempted to write None content for %s", output_path)
            return False
        try:
            dir_path = os.path.dirname(output_path)
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(content)

            self._add_generated_file(output_path)

            print(f"  Successfully generated {output_path}")
            return True
        except IOError as e:
            print(f"Error writing to file {output_path}: {e}")
            return False

    def _prepare_organisation_context(self) -> dict[str, Any]:
        """Prepares the context for the organisation.tfvars template.

        This method scans all resources across all projects to find the unique
        Google Cloud APIs that need to be enabled.

        Returns:
          A context dictionary with a single key, 'project_apis'. The value is
          another dictionary that maps each project ID to a sorted list of the
          API service names required by the resources in that project.
        """
        project_apis: dict[str, set[str]] = DefaultDict(set)
        for project in self._config.get("projects", []):
            project_id = project.get("projectId")
            if not project_id:
                continue
            for _, resource_list in project.items():
                if isinstance(resource_list, list):
                    for resource in resource_list:
                        res_type = resource.get("type")
                        res_info = self._supported_resources.get(res_type)
                        if res_info and (discoveryUrl := res_info.get("discoveryUrl")):
                            if api_service := _extract_api_service_name(discoveryUrl):
                                project_apis[project_id].add(api_service)
        return {
            "projectApis": {pid: sorted(apis) for pid, apis in project_apis.items()}
        }

    def _prepare_networking_context(self) -> dict[str, Any] | None:
        """Prepares the context for the networking.tfvars template."""
        all_projects = self._config.get("projects", [])
        host_projects = [p for p in all_projects if p.get("vpc")]

        if not host_projects:
            logger.warning(
                "No VPC definition found. Cannot generate networking.tfvars."
            )
            return None

        network_project = None
        # Use the explicitly flagged host project if it exists, now with camelCase
        explicit_host = next((p for p in host_projects if p.get("hostProject")), None)

        if explicit_host:
            network_project = explicit_host
        elif len(host_projects) > 1:
            # AMBIGUOUS CASE: Multiple VPCs found, but none are explicitly flagged.
            project_ids = [p.get("projectId") for p in host_projects]
            logger.error(
                "Configuration is ambiguous: Found %d projects with VPCs (%s) "
                "but none have the 'hostProject: true' flag. Please set "
                "the flag on exactly one host project to resolve ambiguity.",
                len(host_projects),
                ", ".join(project_ids),
            )
            raise ValueError("Ambiguous Shared VPC host configuration.")
        else:
            # IMPLICIT CASE: Exactly one project has a VPC. Treat it as the host.
            network_project = host_projects[0]

        primary_vpc = network_project.get("vpc")[0]

        # Determine if it's a shared VPC host by seeing if other projects will be attached.
        sharedVpcServiceProjects = []
        hostProjectId = network_project.get("projectId")
        for project in all_projects:
            if project.get("projectId") != hostProjectId:
                sharedVpcServiceProjects.append(project.get("projectId"))

        isHostProject = bool(sharedVpcServiceProjects)

        # All keys in the context dictionary are now camelCase.
        # All .get() lookups from the config also use camelCase.
        context = {
            "projectId": network_project.get("projectId"),
            "networkName": primary_vpc.get("name"),
            "region": self._config.get("defaultRegion", ""),
            "subnetsData": network_project.get("subnets", []),
            "createNat": "true" if primary_vpc.get("createNat") else "false",
            "sharedVpcHost": "true" if isHostProject else "false",
            "createInterconnect": (
                "true" if primary_vpc.get("createInterconnect") else "false"
            ),
            "createScpPolicy": (
                "true" if primary_vpc.get("createScpPolicy") else "false"
            ),
            "subnetsForScpPolicy": sorted(primary_vpc.get("subnetsForScpPolicy", [])),
            "createHavpn": ("true" if primary_vpc.get("haVpnGateways") else "false"),
            "primaryVpc": primary_vpc,
            "sharedVpcServiceProjects": sharedVpcServiceProjects,
        }
        return context

    def _prepare_psc_context(self) -> dict[str, Any]:
        """Prepares the context for the producer-connectivity.tfvars template.

        This method finds all derived forwarding rules that represent PSC
        endpoints and gathers the necessary data about both the endpoint itself and
        the original producer it targets.

        Returns:
          A context dictionary with a single key, 'psc_endpoints_data'. The value
          is a list of dictionaries, where each dictionary represents one PSC
          endpoint and contains keys like 'endpoint_project_id', 'producer_type',
          and 'producer_name'.
        """
        pscEndpoints = []
        all_projects = self._config.get("projects", [])
        for project in all_projects:
            for fr in project.get("forwardingRules", []):
                producerName = fr.get("targetProducerName")
                if not producerName:
                    continue
                original_producer, producerProjectId = (None, None)
                for p_proj in all_projects:
                    found_producer = next(
                        (
                            p
                            for p in p_proj.get("producers", [])
                            if p.get("name") == producerName
                        ),
                        None,
                    )
                    if found_producer:
                        original_producer = found_producer
                        producerProjectId = p_proj.get("projectId")
                        break
                if not original_producer or not producerProjectId:
                    logger.warning(
                        "Could not find original producer '%s' or its parent project ID. "
                        "Skipping PSC endpoint generation for this target.",
                        producerName,
                    )
                    continue

                endpoint_data = {
                    "endpointProjectId": project.get("projectId"),
                    "producerInstanceProjectId": producerProjectId,
                    "subnetworkName": fr.get("subnetwork", "").split("/")[-1],
                    "networkName": fr.get("network", "").split("/")[-1],
                    "ipAddressName": fr.get("IPAddress", "").split("/")[-1],
                    "region": fr.get("region"),
                    "producerType": original_producer.get("type"),
                    "producerName": original_producer.get("name"),
                    "producer": original_producer,
                }
                pscEndpoints.append(endpoint_data)

        return {"pscEndpointsData": pscEndpoints}

    def generate_organisation_tfvars(
        self, template_name: str = "organisation.tfvars.j2"
    ) -> str | None:
        """Renders the organisation.tfvars file by preparing and passing context.

        Args:
          template_name: The name of the Jinja2 template file.

        Returns:
          A string containing the rendered .tfvars file content, or None on
          a template rendering failure.
        """
        logger.info("Generating organisation.tfvars content.")
        context = self._prepare_organisation_context()
        return jinja_renderer.render_template(
            self._templates_base_dir, template_name, context
        )

    def generate_networking_tfvars(
        self, template_name: str = "networking.tfvars.j2"
    ) -> str | None:
        """Renders the networking.tfvars file by preparing and passing context.

        Args:
          template_name: The name of the Jinja2 template file.

        Returns:
          A string containing the rendered .tfvars file content. Returns an empty
          string if the helper context could not be prepared (e.g., no VPC).
          Returns None on a template rendering failure.
        """
        logger.info("Generating networking.tfvars content.")
        context = self._prepare_networking_context()
        if not context:
            return ""
        return jinja_renderer.render_template(
            self._templates_base_dir, template_name, context
        )

    def generate_producer_connectivity_tfvars(
        self, template_name: str = "producer-connectivity.tfvars.j2"
    ) -> str | None:
        """Renders the producer-connectivity.tfvars file by preparing context.

        Args:
          template_name: The name of the Jinja2 template file.

        Returns:
          A string containing the rendered .tfvars file content. Returns an empty
          string if no PSC endpoints are found. Returns None on a template
          rendering failure.
        """
        logger.info("Generating producer-connectivity.tfvars content.")
        context = self._prepare_psc_context()
        if not context.get("pscEndpointsData"):
            logger.info(
                "No valid PSC endpoints were processed. Skipping"
                " producer-connectivity.tfvars."
            )
            return ""
        return jinja_renderer.render_template(
            self._templates_base_dir, template_name, context
        )

    def _prepare_resource_files_contexts(self) -> list[dict[str, Any]]:
        """Prepares a list of contexts for all per-resource files (YAMLs/tfvars).

        This method iterates through all producers and consumers, checking if they
        require a YAML config or a security .tfvars file to be generated based
        on the 'generationConfig' and 'securityConfigTemplate' keys in
        supported_resources.json.

        Returns:
            A list of dictionaries. Each dictionary represents a file to be
            generated and contains keys like 'output_path', 'template_dir',
            'template_name', and 'context'.
        """
        files_to_generate = []
        all_projects = self._config.get("projects", [])
        network_project = next((p for p in all_projects if p.get("vpc")), None)

        for project in all_projects:
            project_id = project.get("projectId")
            for category in ["producers", "consumers"]:
                for item in project.get(category, []):
                    res_info = self._supported_resources.get(item.get("type"), {})

                    # --- Handle Per-Resource YAML Generation ---
                    if gen_config := res_info.get("generationConfig"):
                        folderName = gen_config.get("folderName")
                        templateFilename = gen_config.get("templateFilename")
                        if folderName and templateFilename:
                            files_to_generate.append(
                                {
                                    "output_path": os.path.join(
                                        (
                                            PRODUCERS_YAML_OUTPUT_DIR_NAME
                                            if category == "producers"
                                            else CONSUMERS_YAML_OUTPUT_DIR_NAME
                                        ),
                                        folderName,
                                        "config",
                                        f"{item.get('name')}.yaml",
                                    ),
                                    "template_dir": os.path.join(
                                        TEMPLATES_BASE_DIR,
                                        category,
                                        folderName,
                                        "config",
                                    ),
                                    "template_name": templateFilename,
                                    "context": {
                                        "projectId": project_id,
                                        "instance": item,
                                    },
                                }
                            )

                    # --- Handle Per-Resource Security TFVars Generation ---
                    if tmpl := res_info.get("securityConfigTemplate"):
                        if network_project:
                            network_path = (
                                f"projects/{network_project.get('projectId')}/global/"
                                f"networks/{network_project.get('vpc', [{}])[0].get('name')}"
                            )
                            files_to_generate.append(
                                {
                                    "output_path": os.path.join(
                                        "security", tmpl.replace(".j2", "")
                                    ),
                                    "template_dir": os.path.join(
                                        TEMPLATES_BASE_DIR, "security"
                                    ),
                                    "template_name": tmpl,
                                    "context": {
                                        "projectId": network_project.get("projectId"),
                                        "networkPath": network_path,
                                    },
                                }
                            )
        return files_to_generate

    def generate_all_resource_files(self) -> dict[str, str] | None:
        """Renders all per-resource YAML and security .tfvars files.

        This method orchestrates the generation of all individual resource
        configuration files, returning a dictionary of their intended file paths
        and rendered content.

        Returns:
            A dictionary mapping the relative output file path to its rendered
            string content, or None on failure.
        """
        logger.info("Generating all per-resource YAML and security files.")
        rendered_files = {}

        # Get the list of all files and contexts that need to be generated
        files_to_generate = self._prepare_resource_files_contexts()
        if not files_to_generate:
            logger.info("No per-resource files needed for this configuration.")
            return {}

        # Render each file
        for file_spec in files_to_generate:
            content = jinja_renderer.render_template(
                file_spec["template_dir"],
                file_spec["template_name"],
                file_spec["context"],
            )
            if content is None:
                logger.error(
                    "Failed to render template for %s", file_spec["output_path"]
                )
                return None  # Return None on any rendering failure
            rendered_files[file_spec["output_path"]] = content
        return rendered_files
